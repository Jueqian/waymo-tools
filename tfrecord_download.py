from huggingface_hub import snapshot_download
import tensorflow as tf
import os
import time
import shutil
from datetime import datetime



segment_str = "segment-1"


def huggingfaceeeeee(data_dir):
    snapshot_download(
        repo_id="AnnaZhang/waymo_open_dataset_v_1_4_3",
        repo_type="dataset",
        local_dir=data_dir,
        # ä½¿ç”¨é€šé…ç¬¦åŒ¹é…ç‰¹å®šæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰ .tfrecord æ–‡ä»¶
        allow_patterns=[f"individual_files/training/{segment_str}*.tfrecord"],
        local_dir_use_symlinks=False,
        resume_download=True,
        # å¦‚æœæ–‡ä»¶å¾ˆå¤šï¼Œå»ºè®®å¢åŠ çº¿ç¨‹æ•°æé«˜é€Ÿåº¦
        max_workers=2
    )


def is_storage_sufficient(data_dir, min_gb_required=30):
    """
    æ£€æŸ¥å‰©ä½™ç©ºé—´æ˜¯å¦å¤§äºè®¾å®šé˜ˆå€¼ï¼ˆé»˜è®¤ 30GBï¼‰
    """
    # å¦‚æœç›®å½•è¿˜æ²¡åˆ›å»ºï¼Œæ£€æŸ¥å…¶çˆ¶ç›®å½•
    check_path = data_dir
    while not os.path.exists(check_path):
        check_path = os.path.dirname(check_path)
        
    _, _, free = shutil.disk_usage(check_path)
    free_gb = free / (1024**3)
    
    if free_gb < min_gb_required:
        print(f"âš ï¸ è­¦å‘Š: ç£ç›˜å‰©ä½™ç©ºé—´ä»…å‰© {free_gb:.2f} GBï¼Œä½äºé˜ˆå€¼ {min_gb_required} GBï¼")
        return False
    return True


def validate_tfrecord(data_dir):
    # 1. åŠ è½½å·²ç»æ ¡éªŒæˆåŠŸçš„åå•ï¼Œé¿å…é‡å¤åŠ³åŠ¨
    success_log = os.path.join(data_dir, "valid_files.txt")
    fail_log = os.path.join(data_dir, "bad_record.txt")
    verified_files = set()
    if os.path.exists(success_log):
        with open(success_log, "r", encoding="utf-8") as f:
            verified_files = {line.strip() for line in f if line.strip()}

    # è·å–ç›®å½•ä¸‹æ‰€æœ‰ tfrecord
    all_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.tfrecord')]
    
    # è¿‡æ»¤æ‰å·²ç»æ ¡éªŒè¿‡çš„
    files_to_check = [f for f in all_files if f not in verified_files]
    
    if not files_to_check:
        print("â˜• æ‰€æœ‰æœ¬åœ°æ–‡ä»¶å·²é€šè¿‡å†å²æ ¡éªŒï¼Œè·³è¿‡æ£€æŸ¥ã€‚")
        return

    print(f"ğŸ” æ­£åœ¨æ ¡éªŒ {len(files_to_check)} ä¸ªæ–°æ–‡ä»¶...")

    with open(fail_log, "a", encoding="utf-8") as bad_log, \
         open(success_log, "a", encoding="utf-8") as good_log:
         
        for f in files_to_check:
            try:
                # æ ¡éªŒé€»è¾‘
                for _ in tf.data.TFRecordDataset(f):
                    pass
                
                # æ ¡éªŒé€šè¿‡ï¼šæ‰“å°å¹¶è®°å½•
                print(f"OK: {f}")
                good_log.write(f + "\n")
                good_log.flush()
                
            except Exception as e:
                now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                error_msg = f"[{now}] [FAILED]: {f}"
                print(error_msg)
                
                bad_log.write(error_msg + "\n") 
                bad_log.flush() 
                
                # åˆ é™¤æŸåæ–‡ä»¶ï¼Œè¿™æ ·ä¸‹æ¬¡ HF é‡å¯ä¼šè‡ªåŠ¨è¡¥ä¸‹
                if os.path.exists(f):
                    os.remove(f)
                    print(f"Deleted corrupted file: {f}")




def download_with_retries(data_dir):

    os.makedirs(data_dir, exist_ok=True)

    max_retries = 150000
    attempt = 0

    print("\n\n\n\n\n\n\n")
    validate_tfrecord(data_dir)

    while attempt < max_retries:
        try:
            # ä¸‹è½½è·¯å¾„å’Œé…ç½®
            if not is_storage_sufficient(data_dir, 20): # è‡³å°‘é¢„ç•™ 20GB
                now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                print(f"[{now}] âŒ ç©ºé—´ä¸è¶³ï¼Œç¨‹åºæš‚åœã€‚æ¸…ç†ç£ç›˜åè‡ªåŠ¨é‡è¯•ã€‚")
                time.sleep(60)
                continue
            huggingfaceeeeee(data_dir)
            print("ğŸ‰ Download completed successfully.")
            break  # æˆåŠŸä¸‹è½½åé€€å‡ºå¾ªç¯
        except Exception as e:
            attempt += 1
            wait_time = 5
            print(f"ğŸ˜¡ Download failed (attempt {attempt}/{max_retries}): {e}. Retrying in {wait_time} seconds...")
            print(f"å¯åŠ¨æ–‡ä»¶æ£€æµ‹...")
            validate_tfrecord(data_dir)
            time.sleep(wait_time)


if __name__ == "__main__":

    data_dir = "/data/repo/waymo/"

    download_with_retries(data_dir)

